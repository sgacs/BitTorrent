{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4625cb7d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65349474",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulates one file being shared amongst a set of peers.  The file is divided into a set of pieces, each comprised of some number of blocks.  There are two types of peers:\n",
    "  - seeds, which start with all the pieces.  \n",
    "  - regular peers, which start with no pieces.\n",
    "\n",
    "The simulation proceeds in rounds.  In each round, peers can request pieces from other peers, and then decide how much to upload to others.  Once every peer has every piece, the simulation ends.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dee377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import sys\n",
    "import logging\n",
    "import copy\n",
    "import itertools\n",
    "import pprint\n",
    "from optparse import OptionParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b992937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from messages import Upload, Request, Download, PeerInfo\n",
    "from util import *\n",
    "from stats import Stats\n",
    "from history import History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cbcb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sim:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.up_bws_state = dict()\n",
    "\n",
    "    \n",
    "    def up_bw(self, peer_id, reinit=False):\n",
    "        \"\"\"Return a consistent bw for this peer\"\"\"\n",
    "        c = self.config\n",
    "        s = self.up_bws_state\n",
    "\n",
    "        # Re-initialize up-bws if we are starting a new simulation\n",
    "        if reinit and peer_id in s:\n",
    "            del s[peer_id]\n",
    "        \n",
    "        \"\"\"Sets the upload bandwidth of seeds to max, other agents at random\"\"\"\n",
    "        if re.match(\"Seed\",peer_id): the_up_bw = c.max_up_bw\n",
    "        else: the_up_bw = random.randint(c.min_up_bw, c.max_up_bw)\n",
    "        \n",
    "        return s.setdefault(peer_id, the_up_bw)\n",
    "\n",
    "    def run_sim_once(self):\n",
    "        \"\"\"Return a history\"\"\"\n",
    "        conf = self.config\n",
    "        # Keep track of the current round.  Needs to be in scope for helpers.\n",
    "        round = 0  \n",
    "\n",
    "        def check_pred(pred, msg, Exc, lst):\n",
    "            \"\"\"Check if any element of lst matches the predicate.  If it does,\n",
    "            raise an exception of type Exc, including the msg and the offending\n",
    "            element.\"\"\"\n",
    "            m = list(map(pred, lst))\n",
    "            if True in m:\n",
    "                i = m.index(True)\n",
    "                raise Exc(msg + \" Bad element: %s\" % lst[i])\n",
    "\n",
    "        def check_uploads(peer, uploads):\n",
    "            \"\"\"Raise an IllegalUpload exception if there is a problem.\"\"\"\n",
    "            def check(pred, msg):\n",
    "                check_pred(pred, msg, IllegalUpload, uploads)\n",
    "\n",
    "            not_upload = lambda o: not isinstance(o, Upload)\n",
    "            check(not_upload, \"List of Uploads contains non-Upload object.\")\n",
    "\n",
    "            self_upload = lambda upload: upload.to_id == peer.id\n",
    "            check(self_upload, \"Can't upload to yourself.\")\n",
    "            \n",
    "            not_from_self = lambda upload: upload.from_id != peer.id\n",
    "            check(not_from_self, \"Upload.from != peer id.\")\n",
    "\n",
    "            check(lambda u: u.bw < 0, \"Upload bandwidth must be non-negative!\")\n",
    "\n",
    "            limit = self.up_bw(peer.id)\n",
    "            if sum([u.bw for u in uploads]) > limit:\n",
    "                raise IllegalUpload(\"Can't upload more than limit of %d. %s\" % (\n",
    "                    limit, uploads))\n",
    "\n",
    "            # If we got here, looks ok.\n",
    "\n",
    "        def check_requests(peer, requests, peer_pieces, available):\n",
    "            \"\"\"Raise an IllegalRequest exception if there is a problem.\"\"\"\n",
    "\n",
    "            def check(pred, msg):\n",
    "                check_pred(pred, msg, IllegalRequest, requests)\n",
    "\n",
    "            check(lambda o: not isinstance(o, Request),\n",
    "                  \"List of Requests contains non-Request object.\")\n",
    "\n",
    "            bad_piece_id = lambda r: (r.piece_id < 0 or\n",
    "                                      r.piece_id >= self.config.num_pieces)\n",
    "            check(bad_piece_id, \"Request asks for non-existent piece!\")\n",
    "            \n",
    "            bad_peer_id = lambda r: r.peer_id not in self.peer_ids\n",
    "            check(bad_peer_id, \"Request mentions non-existent peer!\")\n",
    "\n",
    "            bad_requester_id = lambda r: r.requester_id != peer.id\n",
    "            check(bad_requester_id, \"Request has wrong peer id!\")\n",
    "\n",
    "            bad_start_block = lambda r: (\n",
    "                r.start < 0 or\n",
    "                r.start >= self.config.blocks_per_piece or\n",
    "                r.start > peer_pieces[peer.id][r.piece_id])\n",
    "            # Must request the _next_ necessary block\n",
    "            check(bad_start_block, \"Request has bad start block!\")\n",
    "\n",
    "            def piece_peer_does_not_have(r):\n",
    "                other_peer = self.peers_by_id[r.peer_id]\n",
    "                return r.piece_id not in available[other_peer.id]\n",
    "            check(piece_peer_does_not_have, \"Asking for piece peer does not have!\")\n",
    "            \n",
    "            # If we got here, looks ok\n",
    "\n",
    "        def available_pieces(peer_id, peer_pieces):\n",
    "            \"\"\"\n",
    "            Return a list of piece ids that this peer has available.\n",
    "            \"\"\"\n",
    "            return [i for i in range(conf.num_pieces) if peer_pieces[peer_id][i] == conf.blocks_per_piece]\n",
    "\n",
    "        def peer_done(peer_pieces, peer_id):\n",
    "            # TODO: remove linear pass\n",
    "            for blocks_so_far in peer_pieces[peer_id]:\n",
    "                if blocks_so_far < conf.blocks_per_piece:\n",
    "                    return False\n",
    "            return True\n",
    "            \n",
    "        def all_done(peer_pieces):\n",
    "            result = True\n",
    "            # Check all peers to update done status\n",
    "            for peer_id in peer_pieces:\n",
    "                if peer_done(peer_pieces, peer_id):\n",
    "                    history.peer_is_done(round, peer_id)\n",
    "                else:\n",
    "                    result = False\n",
    "            return result\n",
    "\n",
    "        def create_peers():\n",
    "            \"\"\"Each agent class must be already loaded, and have a\n",
    "            constructor that takes the config, id,  pieces, and\n",
    "            up and down bandwidth, in that order.\"\"\"\n",
    "\n",
    "            def load(class_name, params):\n",
    "                agent_class = conf.agent_classes[class_name]\n",
    "                return agent_class(*params)\n",
    "\n",
    "            counts = dict()\n",
    "            def index(name):\n",
    "                if name in counts:\n",
    "                    a = counts[name]\n",
    "                    counts[name] += 1\n",
    "                else:\n",
    "                    a = 0\n",
    "                    counts[name] = 1\n",
    "                return a\n",
    "\n",
    "            n = len(conf.agent_class_names)\n",
    "            ids = [\"%s%d\" % (n,index(n)) for n in conf.agent_class_names]\n",
    "\n",
    "            is_seed = lambda id: id.startswith(\"Seed\")\n",
    "\n",
    "            def get_pieces(id):\n",
    "                if id.startswith(\"Seed\"):\n",
    "                    return [conf.blocks_per_piece]*conf.num_pieces\n",
    "                else:\n",
    "                    return [0]*conf.num_pieces\n",
    "                \n",
    "            peer_pieces = dict()  # id -> list (blocks / piece)\n",
    "            peer_pieces = dict((id, get_pieces(id)) for id in ids)\n",
    "            pieces = [get_pieces(id) for id in ids]\n",
    "            r = itertools.repeat\n",
    "            \n",
    "            # Re-initialize upload bandwidths at the beginning of each\n",
    "            # new simulation\n",
    "            up_bws = [self.up_bw(id, reinit=True) for id in ids] \n",
    "            params = list(zip(r(conf), ids, pieces, up_bws))\n",
    "\n",
    "            peers = list(map(load, conf.agent_class_names, params))\n",
    "            #logging.debug(\"Peers: \\n\" + \"\\n\".join(str(p) for p in peers))\n",
    "            return peers, peer_pieces\n",
    "\n",
    "        def get_peer_requests(p, peer_info, peer_history, peer_pieces, available):\n",
    "            def remove_me(info):\n",
    "                # TODO: Do we need this linear pass?\n",
    "                return [peer for peer in peer_info if peer.id != p.id]\n",
    "\n",
    "            pieces = copy.copy(peer_pieces[p.id])\n",
    "            # Made copy of pieces and the peer info this peer needs to make it's\n",
    "            # decision, so that it can't change the simulation's copies.\n",
    "            p.update_pieces(pieces)\n",
    "            rs = p.requests(remove_me(peer_info), peer_history)\n",
    "            check_requests(p, rs, peer_pieces, available)\n",
    "            return rs\n",
    "\n",
    "        def get_peer_uploads(all_requests, p, peer_info, peer_history):\n",
    "            def remove_me(info):\n",
    "                # TODO: remove this pass?  Use a set?\n",
    "                return [peer for peer in peer_info if peer.id != p.id]\n",
    "\n",
    "            def requests_to(id):\n",
    "                f = lambda r: r.peer_id == id\n",
    "                ans = []\n",
    "                for rs in list(all_requests.values()):\n",
    "                    ans.extend(list(filter(f, rs)))\n",
    "                return ans\n",
    "\n",
    "            requests = requests_to(p.id)\n",
    "\n",
    "            us = p.uploads(requests, remove_me(peer_info), peer_history)\n",
    "            check_uploads(p, us)\n",
    "            return us\n",
    "\n",
    "        def upload_rate(uploads, uploader_id, requester_id):\n",
    "            \"\"\"\n",
    "            return the uploading rate from uploader to requester\n",
    "            in blocks per time period, or 0 if not uploading.\n",
    "            \"\"\"\n",
    "            for u in uploads[uploader_id]:\n",
    "                if u.to_id == requester_id:\n",
    "                    return u.bw\n",
    "            return 0\n",
    "\n",
    "        def update_peer_pieces(peer_pieces, requests, uploads, available):\n",
    "            \"\"\"\n",
    "            Process the uploads: figure out how many blocks of all the requested\n",
    "            pieces the requesters ended up with.\n",
    "            Make sure requesting the same thing from lots of peers doesn't\n",
    "            stack.\n",
    "            update the sets of available pieces as needed.\n",
    "            \"\"\"\n",
    "            downloads = dict()  # peer_id -> [downloads]\n",
    "            new_pp = copy.deepcopy(peer_pieces)\n",
    "            for requester_id in requests:\n",
    "                downloads[requester_id] = list()\n",
    "            for requester_id in requests:\n",
    "                # Keep track of how many blocks of each piece this\n",
    "                # requester got.  piece -> (blocks, from_who)\n",
    "                new_blocks_per_piece = dict()\n",
    "                def update_count(piece_id, blocks, peer_id):\n",
    "                    if piece_id in new_blocks_per_piece:\n",
    "                        old = new_blocks_per_piece[piece_id][0]\n",
    "                        if blocks > old:\n",
    "                            new_blocks_per_piece[piece_id] = (blocks, peer_id)\n",
    "                    else:\n",
    "                        new_blocks_per_piece[piece_id] = (blocks, peer_id)\n",
    "\n",
    "                # Group the requests by peer that is being asked\n",
    "                get_peer_id = lambda r: r.peer_id\n",
    "                rs = sorted(requests[requester_id], key=get_peer_id)\n",
    "                for peer_id, rs_for_peer in itertools.groupby(rs, get_peer_id):\n",
    "                    bw = upload_rate(uploads, peer_id, requester_id)\n",
    "                    if bw == 0:\n",
    "                        continue\n",
    "                    # This bandwidth gets applied in order to each piece requested\n",
    "                    for r in rs_for_peer:\n",
    "                        needed_blocks = conf.blocks_per_piece - r.start\n",
    "                        alloced_bw = min(bw, needed_blocks)\n",
    "                        update_count(r.piece_id, alloced_bw, peer_id)\n",
    "                        bw -= alloced_bw\n",
    "                        if bw == 0:\n",
    "                            break\n",
    "                for piece_id in new_blocks_per_piece:\n",
    "                    (blocks, peer_id) = new_blocks_per_piece[piece_id]\n",
    "                    new_pp[requester_id][piece_id] += blocks\n",
    "                    if new_pp[requester_id][piece_id] == conf.blocks_per_piece:\n",
    "                        available[requester_id].add(piece_id)\n",
    "                    d = Download(peer_id, requester_id, piece_id, blocks)\n",
    "                    downloads[requester_id].append(d)\n",
    "                \n",
    "            return (new_pp, downloads)\n",
    "\n",
    "        def completed_pieces(peer_id, available):\n",
    "            return len(available[peer_id])\n",
    "        \n",
    "        def log_peer_info(peer_pieces, available):\n",
    "            for p_id in self.peer_ids:\n",
    "                pieces = peer_pieces[p_id]\n",
    "                logging.debug(\"pieces for %s: %s\" % (str(p_id), str(pieces)))\n",
    "            log = \", \".join(\"%s:%s\" % (p_id, completed_pieces(p_id, available))\n",
    "                            for p_id in self.peer_ids)\n",
    "            logging.info(\"Pieces completed: \" + log)\n",
    "\n",
    "\n",
    "        logging.debug(\"Starting simulation with config: %s\" % str(conf))\n",
    "\n",
    "        peers, peer_pieces = create_peers()\n",
    "        self.peer_ids = [p.id for p in peers]\n",
    "        self.peers_by_id = dict((p.id, p) for p in peers)\n",
    "        \n",
    "        upload_rates = dict((id, self.up_bw(id)) for id in self.peer_ids)\n",
    "        history = History(self.peer_ids, upload_rates)\n",
    "\n",
    "        # dict : pid -> set(finished / available pieces)\n",
    "        available = dict((pid, set(available_pieces(pid, peer_pieces)))\n",
    "                         for pid in self.peer_ids)\n",
    "\n",
    "        # Begin the event loop\n",
    "        while True:\n",
    "            logging.info(\"======= Round %d ========\" % round)\n",
    "\n",
    "            peer_info = [PeerInfo(p.id, available[p.id])\n",
    "                         for p in peers]\n",
    "            requests = dict()  # peer_id -> list of Requests\n",
    "            uploads = dict()   # peer_id -> list of Uploads\n",
    "            h = dict()\n",
    "            for p in peers:\n",
    "                h[p.id] = history.peer_history(p.id)\n",
    "                requests[p.id] = get_peer_requests(p, peer_info, h[p.id], peer_pieces,\n",
    "                                                   available)\n",
    "\n",
    "            for p in peers:\n",
    "                uploads[p.id] = get_peer_uploads(requests, p, peer_info, h[p.id])\n",
    "                \n",
    "\n",
    "            (peer_pieces, downloads) = update_peer_pieces(\n",
    "                peer_pieces, requests, uploads, available)\n",
    "            history.update(downloads, uploads)\n",
    "\n",
    "            logging.debug(history.pretty_for_round(round))\n",
    "\n",
    "            log_peer_info(peer_pieces, available)\n",
    "           \n",
    "            if all_done(peer_pieces):\n",
    "                logging.info(\"All done!\")                    \n",
    "                break\n",
    "            round += 1\n",
    "            if round > conf.max_round:\n",
    "                logging.info(\"Out of time.  Stopping.\")\n",
    "                break\n",
    "\n",
    "        logging.info(\"Game history:\\n%s\" % history.pretty())\n",
    "\n",
    "        logging.info(\"======== STATS ========\")\n",
    "        logging.info(\"Uploaded blocks:\\n%s\" %\n",
    "                     Stats.uploaded_blocks_str(self.peer_ids, history))\n",
    "        logging.info(\"Completion rounds:\\n%s\" %\n",
    "                     Stats.completion_rounds_str(self.peer_ids, history))\n",
    "        logging.info(\"All done round: %s\" %\n",
    "                     Stats.all_done_round(self.peer_ids, history))\n",
    "\n",
    "        return history\n",
    "\n",
    "    def run_sim(self):\n",
    "        histories = [self.run_sim_once() for i in range(self.config.iters)]\n",
    "        logging.warning(\"======== SUMMARY STATS ========\")\n",
    "        \n",
    "        uploaded_blocks = [Stats.uploaded_blocks(self.peer_ids, h) for h in histories]\n",
    "        completion_rounds = [Stats.completion_rounds(self.peer_ids, h) for h in histories]\n",
    "\n",
    "        def extract_by_peer_id(lst, peer_id):\n",
    "            \"\"\"Given a list of dicts, pull out the entry\n",
    "            for peer_id from each dict.  Return a list\"\"\"\n",
    "            return [d[peer_id] for d in lst]\n",
    "\n",
    "        uploaded_by_id = dict(\n",
    "            (p_id, extract_by_peer_id(uploaded_blocks, p_id))\n",
    "            for p_id in self.peer_ids)\n",
    "\n",
    "        completion_by_id = dict(\n",
    "            (p_id, extract_by_peer_id(completion_rounds, p_id))\n",
    "            for p_id in self.peer_ids)\n",
    "\n",
    "        logging.warning(\"Uploaded blocks: avg (stddev)\")\n",
    "        for p_id in sorted(self.peer_ids,\n",
    "                           key=lambda id: mean(uploaded_by_id[id])):\n",
    "            us = uploaded_by_id[p_id]\n",
    "            logging.warning(\"%s: %.1f  (%.1f)\" % (p_id, mean(us), stddev(us)))\n",
    "\n",
    "        logging.warning(\"Completion rounds: avg (stddev)\")\n",
    "\n",
    "        def optionize(f):\n",
    "            def g(lst):\n",
    "                if None in lst:\n",
    "                    return None\n",
    "                else:\n",
    "                    return f(lst)\n",
    "            return g\n",
    "\n",
    "        opt_mean = optionize(mean)\n",
    "        opt_stddev = optionize(stddev)\n",
    "        \n",
    "        for p_id in sorted(self.peer_ids,\n",
    "                           key=lambda id: opt_mean(completion_by_id[id]) or -1):\n",
    "            cs = completion_by_id[p_id]\n",
    "            logging.warning(\"%s: %s  (%s)\" % (p_id, opt_mean(cs), opt_stddev(cs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731e6134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c2b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logging(loglevel):\n",
    "    numeric_level = getattr(logging, loglevel.upper(), None)\n",
    "    if not isinstance(numeric_level, int):\n",
    "        raise ValueError('Invalid log level: %s' % loglevel)\n",
    "\n",
    "    root_logger = logging.getLogger('')\n",
    "    strm_out = logging.StreamHandler(sys.stdout)\n",
    "#    strm_out.setFormatter(logging.Formatter('%(levelno)s: %(message)s'))\n",
    "    strm_out.setFormatter(logging.Formatter('%(message)s'))\n",
    "    root_logger.setLevel(numeric_level)\n",
    "    root_logger.addHandler(strm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4fcd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_agents(args):\n",
    "    \"\"\"\n",
    "    Each element is a class name like \"Peer\", with an optional\n",
    "    count appended after a comma.  So either \"Peer\", or \"Peer,3\".\n",
    "    Returns an array with a list of class names, each repeated the\n",
    "    specified number of times.\n",
    "    \"\"\"\n",
    "    ans = []\n",
    "    for c in args:\n",
    "        s = c.split(',')\n",
    "        if len(s) == 1:\n",
    "            ans.extend(s)\n",
    "        elif len(s) == 2:\n",
    "            name, count = s\n",
    "            ans.extend([name]*int(count))\n",
    "        else:\n",
    "            raise ValueError(\"Bad argument: %s\\n\" % c)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0054784",
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21bf31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    usage_msg = \"Usage:  %prog [options] PeerClass1[,count] PeerClass2[,count] ...\"\n",
    "    parser = OptionParser(usage=usage_msg)\n",
    "\n",
    "    def usage(msg):\n",
    "        print(\"Error: %s\\n\" % msg)\n",
    "        parser.print_help()\n",
    "        sys.exit()\n",
    "    \n",
    "    parser.add_option(\"--loglevel\",\n",
    "                      dest=\"loglevel\", default=\"info\",\n",
    "                      help=\"Set the logging level: 'debug' or 'info'\")\n",
    "\n",
    "    parser.add_option(\"--num-pieces\",\n",
    "                      dest=\"num_pieces\", default=3, type=\"int\",\n",
    "                      help=\"Set number of pieces in the file\")\n",
    "\n",
    "    parser.add_option(\"--blocks-per-piece\",\n",
    "                      dest=\"blocks_per_piece\", default=4, type=\"int\",\n",
    "                      help=\"Set number of blocks per piece\")\n",
    "\n",
    "    parser.add_option(\"--max-round\",\n",
    "                      dest=\"max_round\", default=5, type=\"int\",\n",
    "                      help=\"Limit on number of rounds\")\n",
    "\n",
    "    parser.add_option(\"--min-bw\",\n",
    "                      dest=\"min_up_bw\", default=4, type=\"int\",\n",
    "                      help=\"Min upload bandwidth\")\n",
    "\n",
    "    parser.add_option(\"--max-bw\",\n",
    "                      dest=\"max_up_bw\", default=10, type=\"int\",\n",
    "                      help=\"Max upload bandwidth\")\n",
    "\n",
    "    parser.add_option(\"--iters\",\n",
    "                      dest=\"iters\", default=1, type=\"int\",\n",
    "                      help=\"Number of times to run simulation to get stats\")\n",
    "\n",
    "\n",
    "    (options, args) = parser.parse_args()\n",
    "\n",
    "    # leftover args are class names, with optional counts:\n",
    "    # \"Peer Seed[,4]\"\n",
    "\n",
    "    if len(args) == 0:\n",
    "        # default\n",
    "        agents_to_run = ['Dummy', 'Dummy', 'Seed']\n",
    "    else:\n",
    "        try:\n",
    "            agents_to_run = parse_agents(args)\n",
    "        except ValueError as e:\n",
    "            usage(e)\n",
    "    \n",
    "    configure_logging(options.loglevel)\n",
    "    config = Params()\n",
    "\n",
    "    config.add(\"agent_class_names\", agents_to_run)\n",
    "    config.add(\"agent_classes\", load_modules(config.agent_class_names))\n",
    "\n",
    "    \n",
    "    config.add(\"num_pieces\", options.num_pieces)\n",
    "    config.add(\"blocks_per_piece\",options.blocks_per_piece)\n",
    "    config.add(\"max_round\", options.max_round)\n",
    "    config.add(\"min_up_bw\", options.min_up_bw)\n",
    "    config.add(\"max_up_bw\", options.max_up_bw)\n",
    "    config.add(\"iters\", options.iters)\n",
    "    \n",
    "    sim = Sim(config)\n",
    "    sim.run_sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1699dc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # The next two lines are for profiling...\n",
    "    import cProfile\n",
    "    cProfile.run('main(sys.argv)', 'out.prof')\n",
    "#    main(sys.argv)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
